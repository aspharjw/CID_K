{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "    \n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "    \n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from rnn.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable   \n",
    "\n",
    "sys.path.append(\"../Preprocessor\")\n",
    "import format_module\n",
    "\n",
    "import rnn\n",
    "import naivebayesian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 100  # word2vec k size\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class classifierModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classifierModule, self).__init__()\n",
    "        self.rnn_model = rnn.RNN_model(input_size)\n",
    "        \n",
    "        self.nb_model = naivebayesian.NaiveBayesianDB()\n",
    "        #TODO\n",
    "        \n",
    "    def encoder(self, formattedList):\n",
    "        length = len(formattedList)\n",
    "        contextList = [formattedList[i].context for i in range(length)]\n",
    "\n",
    "        lengths = torch.LongTensor([len(contextList[i]) for i in range(length)])\n",
    "        max_len = torch.max(lengths)\n",
    "        \n",
    "        data = np.zeros((length, max_len, input_size))\n",
    "\n",
    "        for i in range(length):\n",
    "            context = contextList[i]\n",
    "            if not (context.size == 0):\n",
    "                data[i, :context.shape[0],:] = context\n",
    "            else:\n",
    "                lengths[i] = 1\n",
    "            i+=1\n",
    "            \n",
    "        return self.sort_batch(torch.FloatTensor(data), formattedList, lengths)\n",
    "        \n",
    "    def sort_batch(self, context, formatted, seq_len):\n",
    "        batch_size = context.size(0)\n",
    "        sorted_seq_len, sorted_idx = seq_len.sort(0, descending = True)\n",
    "        \n",
    "        sorted_context = context[sorted_idx]\n",
    "        sorted_formatted = [formatted[i] for i in sorted_idx]\n",
    "\n",
    "        for f in sorted_formatted:\n",
    "            print(len(f.context))\n",
    "        \n",
    "        return Variable(sorted_context), sorted_formatted, sorted_seq_len\n",
    "    \n",
    "    def resize_input(self, input):\n",
    "        list_ = list()\n",
    "        for i in range(0, len(input), batch_size):\n",
    "            list_.append(input[i:i+batch_size])\n",
    "        return list_\n",
    "        \n",
    "    def forward(self, formatted_list, hidden=None):\n",
    "        context, formatted, lengths = self.encoder(bl)\n",
    "        \n",
    "        print(self.rnn_model(context, lengths))\n",
    "        self.nb_model.naive_bayes_FRlist(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "120\n",
      "52\n",
      "42\n",
      "34\n",
      "32\n",
      "27\n",
      "25\n",
      "20\n",
      "9\n",
      "Variable containing:\n",
      " 0.0424  0.0017 -0.0005 -0.1110 -0.0789 -0.1283  0.0683  0.3316 -0.0707 -0.0331\n",
      " 0.0500 -0.0129 -0.0122 -0.1034 -0.1012 -0.1576  0.0671  0.3592 -0.0847 -0.0408\n",
      " 0.0423 -0.0216 -0.0013 -0.1034 -0.0985 -0.1413  0.0588  0.3512 -0.0702 -0.0477\n",
      " 0.0392 -0.0084 -0.0292 -0.1154 -0.1240 -0.1373  0.0695  0.3633 -0.0967 -0.0507\n",
      " 0.0162  0.0086 -0.0039 -0.1015 -0.0975 -0.1300  0.0643  0.3492 -0.0805 -0.0432\n",
      " 0.0217 -0.0092 -0.0124 -0.1111 -0.1155 -0.1357  0.0437  0.3523 -0.0628 -0.0476\n",
      " 0.0441 -0.0013  0.0036 -0.1084 -0.0750 -0.1597  0.0634  0.3446 -0.0807 -0.0296\n",
      " 0.0308 -0.0167 -0.0239 -0.0983 -0.1318 -0.1451  0.0415  0.3690 -0.0910 -0.0569\n",
      " 0.0418 -0.0023 -0.0006 -0.1072 -0.1042 -0.1334  0.0526  0.3461 -0.0762 -0.0459\n",
      " 0.0484 -0.0129 -0.0090 -0.0947 -0.1127 -0.1498  0.0464  0.3608 -0.0632 -0.0479\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-bdfaf21d0aff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m#print(formatted_list[0].context.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtest_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatted_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtest_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Program Files\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pre_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-702317148b9a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, formatted_list, hidden)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes_FRlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\Users\\현도\\Documents\\수업자료\\창의적 통합 설계에\\CID_K\\Classifier\\naivebayesian.py\u001b[0m in \u001b[0;36mnaive_bayes_FRlist\u001b[0;34m(self, FRlist)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFRlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mFR\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mFRlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0mv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext_bayes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m             \u001b[0mit\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\Users\\현도\\Documents\\수업자료\\창의적 통합 설계에\\CID_K\\Classifier\\naivebayesian.py\u001b[0m in \u001b[0;36mnaive_bayes\u001b[0;34m(self, postaglist)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[1;31m# p_spam normalize = p_spam/(p_spam+p_ham) = 1/(1+1/p)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m         \u001b[0mp_spam\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mratio_spam\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mp_spam\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[1;31m# print(\"p_spam : \" + str(p_spam))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "formatted_list = load_object(\"../Preprocessor/save_formatted_review.pkl\")\n",
    "test_classifier = classifierModule()\n",
    "\n",
    "test_classifier.nb_model.add_FRlist(formatted_list)\n",
    "\n",
    "batch_list = test_classifier.resize_input(formatted_list)\n",
    "for bl in batch_list:\n",
    "    test_classifier(bl)\n",
    "\n",
    "for param in test_classifier.parameters():\n",
    "     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㄹ', 'ㄷ', 'ㄴ', 'ㅁ', 'ㄱ']\n",
      "['ㄱ', 'ㅁ', 'ㄴ', 'ㄷ', 'ㄹ']\n"
     ]
    }
   ],
   "source": [
    "a = [\"ㄱ\", \"ㄴ\", \"ㄷ\", \"ㄹ\", \"ㅁ\"]\n",
    "b = [4, 3, 2, 1, 0]\n",
    "c = [4, 2, 1, 0, 3]\n",
    "\n",
    "d = [x for _,x in sorted(zip(c,a))]\n",
    "print(d)\n",
    "list.reverse(d)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10]]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "a_ = list()\n",
    "for i in range(0, len(a), 3):\n",
    "    a_.append(a[i:i+3])\n",
    "print(a_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
