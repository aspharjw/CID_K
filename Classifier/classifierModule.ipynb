{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "    \n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "    \n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from rnn.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable   \n",
    "from torch import optim\n",
    "\n",
    "sys.path.append(\"../Preprocessor\")\n",
    "import format_module\n",
    "\n",
    "import rnn\n",
    "import naivebayesian\n",
    "import cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class classifierModule(nn.Module):\n",
    "    def __init__(self, input_size, batch_size):\n",
    "        super(classifierModule, self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        self.rnn_model = rnn.RNN_model(input_size)\n",
    "        self.rnn_out_size = rnn.hidden_size\n",
    "        #self.rnn_mlp()\n",
    "        \n",
    "        self.nb_model = naivebayesian.NaiveBayesianDB()\n",
    "        \n",
    "        self.cnn_model = cnn.ConvNet(input_size)\n",
    "        #self.cnn_model = \n",
    "        \n",
    "        #TODO\n",
    "        \n",
    "    def encoder(self, formattedList):\n",
    "        length = len(formattedList)\n",
    "        contextList = [formattedList[i].context for i in range(length)]\n",
    "\n",
    "        lengths = torch.LongTensor([len(contextList[i]) for i in range(length)])\n",
    "        max_len = torch.max(lengths)\n",
    "        \n",
    "        data = np.zeros((length, max_len, self.input_size))\n",
    "\n",
    "        for i in range(length):\n",
    "            context = contextList[i]\n",
    "            if not (context.size == 0):\n",
    "                data[i, :context.shape[0],:] = context\n",
    "            else:\n",
    "                lengths[i] = 1\n",
    "            i+=1\n",
    "            \n",
    "        return self.sort_batch(torch.FloatTensor(data), formattedList, lengths)\n",
    "        \n",
    "    def sort_batch(self, context, formatted, seq_len):\n",
    "        batch_size = context.size(0)\n",
    "        sorted_seq_len, sorted_idx = seq_len.sort(0, descending = True)\n",
    "        \n",
    "        sorted_context = context[sorted_idx]\n",
    "        sorted_formatted = [formatted[i] for i in sorted_idx]\n",
    "\n",
    "        for f in sorted_formatted:\n",
    "            print(len(f.context))\n",
    "        \n",
    "        return Variable(sorted_context), sorted_formatted, sorted_seq_len\n",
    "    \n",
    "    def resize_input(self, input):\n",
    "        list_ = list()\n",
    "        for i in range(0, len(input), self.batch_size):\n",
    "            list_.append(input[i:i+self.batch_size])\n",
    "        return list_\n",
    "        \n",
    "    def forward(self, formatted_list, hidden=None):\n",
    "        context, formatted, lengths = self.encoder(bl)\n",
    "        \n",
    "        rnn_out = self.rnn_model(context, lengths)\n",
    "        cnn_out = self.cnn_model(context)\n",
    "        nb_out = self.nb_model.naive_bayes_FRlist(formatted)\n",
    "        \n",
    "        print(\"rnn_out : \", rnn_out, \"\\n\\n\\n\")\n",
    "        print(\"cnn_out : \", cnn_out, \"\\n\\n\\n\")\n",
    "        print(\"nb_out : \", nb_out, \"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "120\n",
      "52\n",
      "42\n",
      "34\n",
      "32\n",
      "27\n",
      "25\n",
      "20\n",
      "9\n",
      "torch.Size([1370, 1])\n",
      "torch.Size([10, 137])\n",
      "[[ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          1.         ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.71666667]\n",
      " [ 0.          1.          0.         ...,  0.          0.          0.        ]]\n",
      "\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  1.0000  ...   0.0000  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.7167\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.DoubleTensor of size 137x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0244  0.2028  0.0507  0.0227  0.2204 -0.1038 -0.0926 -0.1379 -0.2543  0.2713\n",
      "-0.0384  0.2110  0.0677  0.0012  0.2032 -0.0852 -0.0952 -0.1377 -0.2471  0.2632\n",
      "-0.0450  0.2023  0.0615  0.0030  0.2121 -0.0737 -0.0944 -0.1492 -0.2470  0.2622\n",
      "-0.0412  0.2034  0.0561  0.0162  0.2240 -0.0898 -0.0893 -0.1613 -0.2622  0.2811\n",
      "-0.0527  0.2176  0.0587  0.0383  0.2039 -0.0840 -0.0976 -0.1573 -0.3101  0.2662\n",
      "-0.0415  0.2159  0.0476 -0.0194  0.1940 -0.0669 -0.1050 -0.1710 -0.2944  0.2630\n",
      "-0.0380  0.1973  0.0442  0.0321  0.2349 -0.0981 -0.0921 -0.1698 -0.2089  0.2643\n",
      "-0.0239  0.2026  0.0286 -0.0299  0.1852 -0.0426 -0.1120 -0.1807 -0.3245  0.2552\n",
      "-0.0463  0.2136  0.0468  0.0115  0.2262 -0.0846 -0.0891 -0.1652 -0.2494  0.2796\n",
      "-0.0577  0.2186  0.0670 -0.0034  0.1923 -0.0574 -0.0998 -0.1548 -0.2809  0.2426\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762\n",
      " 67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363\n",
      " 53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254\n",
      " 50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937\n",
      " 52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435\n",
      " 50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227\n",
      " 51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750\n",
      " 48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250\n",
      " 46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126\n",
      " 46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056\n",
      "\n",
      "Columns 8 to 15 \n",
      " 64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762\n",
      " 67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363\n",
      " 53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254\n",
      " 50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937\n",
      " 52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435\n",
      " 50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227\n",
      " 51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750\n",
      " 48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250\n",
      " 46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126\n",
      " 46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056\n",
      "\n",
      "Columns 16 to 23 \n",
      " 64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762\n",
      " 67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363\n",
      " 53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254\n",
      " 50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937\n",
      " 52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435\n",
      " 50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227\n",
      " 51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750\n",
      " 48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250\n",
      " 46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126\n",
      " 46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056\n",
      "\n",
      "Columns 24 to 31 \n",
      " 64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762\n",
      " 67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363\n",
      " 53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254\n",
      " 50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937\n",
      " 52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435\n",
      " 50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227\n",
      " 51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750\n",
      " 48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250\n",
      " 46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126\n",
      " 46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056\n",
      "\n",
      "Columns 32 to 39 \n",
      " 64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762\n",
      " 67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363\n",
      " 53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254\n",
      " 50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937\n",
      " 52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435\n",
      " 50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227\n",
      " 51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750\n",
      " 48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250\n",
      " 46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126\n",
      " 46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056\n",
      "\n",
      "Columns 40 to 47 \n",
      " 64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762\n",
      " 67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363\n",
      " 53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254\n",
      " 50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937\n",
      " 52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435\n",
      " 50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227\n",
      " 51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750\n",
      " 48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250\n",
      " 46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126\n",
      " 46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056\n",
      "\n",
      "Columns 48 to 55 \n",
      " 64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762  64.3762\n",
      " 67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363  67.1363\n",
      " 53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254  53.6254\n",
      " 50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937  50.2937\n",
      " 52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435  52.5435\n",
      " 50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227  50.4227\n",
      " 51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750  51.4750\n",
      " 48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250  48.8250\n",
      " 46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126  46.9126\n",
      " 46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056  46.5056\n",
      "\n",
      "Columns 56 to 59 \n",
      " 64.3762  64.3762  64.3762  64.3762\n",
      " 67.1363  67.1363  67.1363  67.1363\n",
      " 53.6254  53.6254  53.6254  53.6254\n",
      " 50.2937  50.2937  50.2937  50.2937\n",
      " 52.5435  52.5435  52.5435  52.5435\n",
      " 50.4227  50.4227  50.4227  50.4227\n",
      " 51.4750  51.4750  51.4750  51.4750\n",
      " 48.8250  48.8250  48.8250  48.8250\n",
      " 46.9126  46.9126  46.9126  46.9126\n",
      " 46.5056  46.5056  46.5056  46.5056\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "141\n",
      "124\n",
      "104\n",
      "71\n",
      "63\n",
      "33\n",
      "27\n",
      "25\n",
      "19\n",
      "7\n",
      "torch.Size([1410, 1])\n",
      "torch.Size([10, 141])\n",
      "[[ 0.    1.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    1.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    1.   ...,  0.    0.    0.  ]\n",
      " ..., \n",
      " [ 0.    1.    0.   ...,  0.    0.    0.  ]\n",
      " [ 0.    0.    0.   ...,  0.    0.    0.65]\n",
      " [ 0.    1.    0.   ...,  0.    0.    0.  ]]\n",
      "\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  1.0000  ...   0.0000  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.6500\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.DoubleTensor of size 141x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0211  0.2120  0.0643 -0.0034  0.2255 -0.1168 -0.0849 -0.1555 -0.2241  0.2797\n",
      "-0.0537  0.2187  0.0481 -0.0003  0.2058 -0.0798 -0.0987 -0.1806 -0.2876  0.2606\n",
      "-0.0264  0.2058  0.0471  0.0029  0.2392 -0.1199 -0.0920 -0.1954 -0.2197  0.2806\n",
      "-0.0567  0.2175  0.0416 -0.0383  0.2057 -0.0774 -0.1053 -0.1721 -0.2920  0.2638\n",
      "-0.0544  0.2094  0.0668  0.0269  0.2131 -0.0830 -0.0806 -0.1647 -0.2661  0.2641\n",
      "-0.0627  0.2126  0.0701  0.0412  0.2044 -0.0722 -0.0802 -0.1560 -0.2700  0.2577\n",
      "-0.0734  0.2239  0.0783  0.0230  0.1912 -0.0725 -0.0850 -0.1476 -0.3070  0.2585\n",
      "-0.0333  0.2174  0.0393 -0.0122  0.1996 -0.0896 -0.1023 -0.1435 -0.3058  0.2627\n",
      "-0.0495  0.2189  0.0513 -0.0450  0.1995 -0.0611 -0.1046 -0.1671 -0.2871  0.2692\n",
      "-0.0179  0.2094  0.0267  0.0357  0.2363 -0.1420 -0.0946 -0.1815 -0.1858  0.2529\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385\n",
      " 60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948\n",
      " 61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347\n",
      " 56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383\n",
      " 54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540\n",
      " 51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212\n",
      " 49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131\n",
      " 50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304\n",
      " 49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390\n",
      " 47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757\n",
      "\n",
      "Columns 8 to 15 \n",
      " 66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385\n",
      " 60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948\n",
      " 61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347\n",
      " 56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383\n",
      " 54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540\n",
      " 51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212\n",
      " 49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131\n",
      " 50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304\n",
      " 49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390\n",
      " 47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757\n",
      "\n",
      "Columns 16 to 23 \n",
      " 66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385\n",
      " 60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948\n",
      " 61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347\n",
      " 56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383\n",
      " 54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540\n",
      " 51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212\n",
      " 49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131\n",
      " 50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304\n",
      " 49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390\n",
      " 47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757\n",
      "\n",
      "Columns 24 to 31 \n",
      " 66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385\n",
      " 60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948\n",
      " 61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347\n",
      " 56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383\n",
      " 54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540\n",
      " 51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212\n",
      " 49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131\n",
      " 50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304\n",
      " 49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390\n",
      " 47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757\n",
      "\n",
      "Columns 32 to 39 \n",
      " 66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385\n",
      " 60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948\n",
      " 61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347\n",
      " 56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383\n",
      " 54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540\n",
      " 51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212\n",
      " 49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131\n",
      " 50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304\n",
      " 49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390\n",
      " 47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757\n",
      "\n",
      "Columns 40 to 47 \n",
      " 66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385\n",
      " 60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948\n",
      " 61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347\n",
      " 56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383\n",
      " 54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540\n",
      " 51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212\n",
      " 49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131\n",
      " 50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304\n",
      " 49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390\n",
      " 47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757\n",
      "\n",
      "Columns 48 to 55 \n",
      " 66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385  66.4385\n",
      " 60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948  60.0948\n",
      " 61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347  61.8347\n",
      " 56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383  56.7383\n",
      " 54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540  54.5540\n",
      " 51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212  51.6212\n",
      " 49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131  49.6131\n",
      " 50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304  50.9304\n",
      " 49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390  49.4390\n",
      " 47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757  47.2757\n",
      "\n",
      "Columns 56 to 59 \n",
      " 66.4385  66.4385  66.4385  66.4385\n",
      " 60.0948  60.0948  60.0948  60.0948\n",
      " 61.8347  61.8347  61.8347  61.8347\n",
      " 56.7383  56.7383  56.7383  56.7383\n",
      " 54.5540  54.5540  54.5540  54.5540\n",
      " 51.6212  51.6212  51.6212  51.6212\n",
      " 49.6131  49.6131  49.6131  49.6131\n",
      " 50.9304  50.9304  50.9304  50.9304\n",
      " 49.4390  49.4390  49.4390  49.4390\n",
      " 47.2757  47.2757  47.2757  47.2757\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "112\n",
      "85\n",
      "83\n",
      "54\n",
      "45\n",
      "28\n",
      "22\n",
      "20\n",
      "13\n",
      "10\n",
      "torch.Size([1120, 1])\n",
      "torch.Size([10, 112])\n",
      "[[ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          1.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.86666667  0.13333333 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.26666667\n",
      "   0.73333333]\n",
      " [ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.13333333]]\n",
      "\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  1.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.8667  0.1333  ...   0.0000  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.2667  0.7333\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.1333\n",
      "[torch.DoubleTensor of size 112x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0621  0.2113  0.0609  0.0094  0.2084 -0.0723 -0.0959 -0.1658 -0.2383  0.2501\n",
      "-0.0463  0.2182  0.0547 -0.0378  0.1833 -0.0538 -0.0983 -0.1707 -0.3297  0.2711\n",
      "-0.0474  0.1982  0.0572  0.0306  0.2197 -0.0856 -0.0909 -0.1698 -0.2159  0.2553\n",
      "-0.0454  0.2196  0.0794 -0.0207  0.1943 -0.0637 -0.0861 -0.1397 -0.2793  0.2774\n",
      "-0.0545  0.2053  0.0665  0.0142  0.2266 -0.0853 -0.0866 -0.1727 -0.2234  0.2721\n",
      "-0.0603  0.2147  0.0789 -0.0224  0.1807 -0.0508 -0.0999 -0.1289 -0.3159  0.2604\n",
      "-0.0474  0.2210  0.0568 -0.0098  0.2050 -0.0770 -0.0954 -0.1627 -0.3109  0.2829\n",
      "-0.0280  0.2008  0.0495  0.0025  0.1905 -0.0498 -0.0969 -0.1629 -0.2982  0.2599\n",
      "-0.0394  0.2241  0.0435 -0.0162  0.2128 -0.0944 -0.1084 -0.1819 -0.3064  0.2675\n",
      "-0.0412  0.2106  0.0678  0.0025  0.1903 -0.0736 -0.0860 -0.1620 -0.2758  0.2639\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737\n",
      " 49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133\n",
      " 51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492\n",
      " 42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458\n",
      " 42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603\n",
      " 40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208\n",
      " 38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038\n",
      " 40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425\n",
      " 38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474\n",
      " 38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734\n",
      "\n",
      "Columns 8 to 15 \n",
      " 54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737\n",
      " 49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133\n",
      " 51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492\n",
      " 42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458\n",
      " 42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603\n",
      " 40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208\n",
      " 38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038\n",
      " 40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425\n",
      " 38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474\n",
      " 38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734\n",
      "\n",
      "Columns 16 to 23 \n",
      " 54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737\n",
      " 49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133\n",
      " 51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492\n",
      " 42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458\n",
      " 42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603\n",
      " 40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208\n",
      " 38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038\n",
      " 40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425\n",
      " 38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474\n",
      " 38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734\n",
      "\n",
      "Columns 24 to 31 \n",
      " 54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737\n",
      " 49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133\n",
      " 51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492\n",
      " 42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458\n",
      " 42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603\n",
      " 40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208\n",
      " 38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038\n",
      " 40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425\n",
      " 38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474\n",
      " 38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734\n",
      "\n",
      "Columns 32 to 39 \n",
      " 54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737\n",
      " 49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133\n",
      " 51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492\n",
      " 42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458\n",
      " 42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603\n",
      " 40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208\n",
      " 38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038\n",
      " 40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425\n",
      " 38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474\n",
      " 38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734\n",
      "\n",
      "Columns 40 to 47 \n",
      " 54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737\n",
      " 49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133\n",
      " 51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492\n",
      " 42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458\n",
      " 42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603\n",
      " 40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208\n",
      " 38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038\n",
      " 40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425\n",
      " 38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474\n",
      " 38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734\n",
      "\n",
      "Columns 48 to 55 \n",
      " 54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737  54.1737\n",
      " 49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133  49.4133\n",
      " 51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492  51.4492\n",
      " 42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458  42.4458\n",
      " 42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603  42.8603\n",
      " 40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208  40.8208\n",
      " 38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038  38.7038\n",
      " 40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425  40.0425\n",
      " 38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474  38.3474\n",
      " 38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734  38.0734\n",
      "\n",
      "Columns 56 to 59 \n",
      " 54.1737  54.1737  54.1737  54.1737\n",
      " 49.4133  49.4133  49.4133  49.4133\n",
      " 51.4492  51.4492  51.4492  51.4492\n",
      " 42.4458  42.4458  42.4458  42.4458\n",
      " 42.8603  42.8603  42.8603  42.8603\n",
      " 40.8208  40.8208  40.8208  40.8208\n",
      " 38.7038  38.7038  38.7038  38.7038\n",
      " 40.0425  40.0425  40.0425  40.0425\n",
      " 38.3474  38.3474  38.3474  38.3474\n",
      " 38.0734  38.0734  38.0734  38.0734\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "86\n",
      "47\n",
      "46\n",
      "33\n",
      "27\n",
      "25\n",
      "15\n",
      "13\n",
      "8\n",
      "6\n",
      "torch.Size([860, 1])\n",
      "torch.Size([10, 86])\n",
      "[[ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          1.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.43333333  0.56666667 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.13333333\n",
      "   0.86666667]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.56666667]]\n",
      "\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  1.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.4333  0.5667  ...   0.0000  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  1.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.1333  0.8667\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.5667\n",
      "[torch.DoubleTensor of size 86x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0293  0.2039  0.0333 -0.0163  0.2008 -0.0635 -0.0981 -0.1536 -0.3135  0.2709\n",
      "-0.0534  0.2170  0.0550 -0.0040  0.1822 -0.0612 -0.0991 -0.1597 -0.3251  0.2589\n",
      "-0.0344  0.2072  0.0641  0.0286  0.2241 -0.1050 -0.0780 -0.1475 -0.2547  0.2765\n",
      "-0.0153  0.2035  0.0414  0.0256  0.2342 -0.1172 -0.0970 -0.1595 -0.2472  0.2809\n",
      "-0.0625  0.2102  0.0684 -0.0079  0.1578 -0.0110 -0.1060 -0.1475 -0.3528  0.2404\n",
      "-0.0711  0.2030  0.0617  0.0324  0.2286 -0.0844 -0.0981 -0.1849 -0.2146  0.2561\n",
      "-0.0518  0.2121  0.0602 -0.0101  0.1653 -0.0266 -0.1097 -0.1535 -0.3244  0.2424\n",
      "-0.0481  0.2135  0.0620  0.0309  0.1979 -0.0807 -0.0880 -0.1187 -0.3142  0.2729\n",
      "-0.0255  0.2025  0.0216  0.0348  0.2355 -0.1375 -0.1026 -0.1799 -0.2109  0.2507\n",
      "-0.0243  0.2103  0.0367  0.0299  0.2156 -0.1193 -0.0889 -0.1681 -0.2388  0.2545\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099\n",
      " 33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507\n",
      " 36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439\n",
      " 33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995\n",
      " 31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187\n",
      " 34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637\n",
      " 31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936\n",
      " 30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828\n",
      " 30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158\n",
      " 29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991\n",
      "\n",
      "Columns 8 to 15 \n",
      " 42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099\n",
      " 33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507\n",
      " 36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439\n",
      " 33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995\n",
      " 31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187\n",
      " 34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637\n",
      " 31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936\n",
      " 30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828\n",
      " 30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158\n",
      " 29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991\n",
      "\n",
      "Columns 16 to 23 \n",
      " 42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099\n",
      " 33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507\n",
      " 36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439\n",
      " 33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995\n",
      " 31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187\n",
      " 34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637\n",
      " 31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936\n",
      " 30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828\n",
      " 30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158\n",
      " 29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991\n",
      "\n",
      "Columns 24 to 31 \n",
      " 42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099\n",
      " 33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507\n",
      " 36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439\n",
      " 33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995\n",
      " 31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187\n",
      " 34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637\n",
      " 31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936\n",
      " 30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828\n",
      " 30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158\n",
      " 29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991\n",
      "\n",
      "Columns 32 to 39 \n",
      " 42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099\n",
      " 33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507\n",
      " 36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439\n",
      " 33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995\n",
      " 31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187\n",
      " 34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637\n",
      " 31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936\n",
      " 30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828\n",
      " 30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158\n",
      " 29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991\n",
      "\n",
      "Columns 40 to 47 \n",
      " 42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099\n",
      " 33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507\n",
      " 36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439\n",
      " 33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995\n",
      " 31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187\n",
      " 34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637\n",
      " 31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936\n",
      " 30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828\n",
      " 30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158\n",
      " 29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991\n",
      "\n",
      "Columns 48 to 55 \n",
      " 42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099  42.8099\n",
      " 33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507  33.6507\n",
      " 36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439  36.4439\n",
      " 33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995  33.6995\n",
      " 31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187  31.7187\n",
      " 34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637  34.7637\n",
      " 31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936  31.2936\n",
      " 30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828  30.3828\n",
      " 30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158  30.4158\n",
      " 29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991  29.3991\n",
      "\n",
      "Columns 56 to 59 \n",
      " 42.8099  42.8099  42.8099  42.8099\n",
      " 33.6507  33.6507  33.6507  33.6507\n",
      " 36.4439  36.4439  36.4439  36.4439\n",
      " 33.6995  33.6995  33.6995  33.6995\n",
      " 31.7187  31.7187  31.7187  31.7187\n",
      " 34.7637  34.7637  34.7637  34.7637\n",
      " 31.2936  31.2936  31.2936  31.2936\n",
      " 30.3828  30.3828  30.3828  30.3828\n",
      " 30.4158  30.4158  30.4158  30.4158\n",
      " 29.3991  29.3991  29.3991  29.3991\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "96\n",
      "73\n",
      "68\n",
      "49\n",
      "41\n",
      "28\n",
      "16\n",
      "15\n",
      "15\n",
      "7\n",
      "torch.Size([960, 1])\n",
      "torch.Size([10, 96])\n",
      "[[ 0.   1.   0.  ...,  0.   0.   0. ]\n",
      " [ 0.   0.   1.  ...,  0.   0.   0. ]\n",
      " [ 0.   0.6  0.4 ...,  0.   0.   0. ]\n",
      " ..., \n",
      " [ 0.   0.   0.  ...,  0.   0.8  0.2]\n",
      " [ 0.   1.   0.  ...,  0.   0.   0. ]\n",
      " [ 0.   0.   0.  ...,  0.   0.   0.4]]\n",
      "\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  1.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.6000  0.4000  ...   0.0000  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.8000  0.2000\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.4000\n",
      "[torch.DoubleTensor of size 96x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0366  0.2052  0.0474  0.0122  0.2280 -0.1002 -0.0896 -0.1797 -0.2231  0.2633\n",
      "-0.0380  0.2124  0.0320 -0.0302  0.2013 -0.0629 -0.1034 -0.1682 -0.3146  0.2692\n",
      "-0.0576  0.2360  0.0661 -0.0524  0.1845 -0.0631 -0.0980 -0.1514 -0.3325  0.2751\n",
      "-0.0360  0.2100  0.0467 -0.0078  0.2017 -0.0841 -0.1010 -0.1428 -0.2919  0.2697\n",
      "-0.0458  0.2223  0.0561 -0.0347  0.1825 -0.0583 -0.0980 -0.1630 -0.3545  0.2719\n",
      "-0.0394  0.2059  0.0521 -0.0043  0.2238 -0.0749 -0.1008 -0.1609 -0.2206  0.2655\n",
      "-0.0427  0.2061  0.0605  0.0372  0.2334 -0.1103 -0.0867 -0.1581 -0.2000  0.2608\n",
      "-0.0472  0.2155  0.0493  0.0088  0.2399 -0.1116 -0.0813 -0.1792 -0.2089  0.2841\n",
      "-0.0145  0.1996  0.0180  0.0329  0.2694 -0.1533 -0.0873 -0.1823 -0.1777  0.2874\n",
      "-0.0261  0.2096  0.0253  0.0116  0.1960 -0.0985 -0.1037 -0.1686 -0.2761  0.2449\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388\n",
      " 43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663\n",
      " 40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851\n",
      " 37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604\n",
      " 36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072\n",
      " 37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986\n",
      " 33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123\n",
      " 33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796\n",
      " 33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796\n",
      " 32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365\n",
      "\n",
      "Columns 8 to 15 \n",
      " 45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388\n",
      " 43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663\n",
      " 40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851\n",
      " 37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604\n",
      " 36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072\n",
      " 37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986\n",
      " 33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123\n",
      " 33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796\n",
      " 33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796\n",
      " 32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365\n",
      "\n",
      "Columns 16 to 23 \n",
      " 45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388\n",
      " 43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663\n",
      " 40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851\n",
      " 37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604\n",
      " 36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072\n",
      " 37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986\n",
      " 33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123\n",
      " 33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796\n",
      " 33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796\n",
      " 32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365\n",
      "\n",
      "Columns 24 to 31 \n",
      " 45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388\n",
      " 43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663\n",
      " 40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851\n",
      " 37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604\n",
      " 36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072\n",
      " 37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986\n",
      " 33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123\n",
      " 33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796\n",
      " 33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796\n",
      " 32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365\n",
      "\n",
      "Columns 32 to 39 \n",
      " 45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388\n",
      " 43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663\n",
      " 40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851\n",
      " 37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604\n",
      " 36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072\n",
      " 37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986\n",
      " 33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123\n",
      " 33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796\n",
      " 33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796\n",
      " 32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365\n",
      "\n",
      "Columns 40 to 47 \n",
      " 45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388\n",
      " 43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663\n",
      " 40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851\n",
      " 37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604\n",
      " 36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072\n",
      " 37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986\n",
      " 33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123\n",
      " 33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796\n",
      " 33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796\n",
      " 32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365\n",
      "\n",
      "Columns 48 to 55 \n",
      " 45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388  45.6388\n",
      " 43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663  43.0663\n",
      " 40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851  40.6851\n",
      " 37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604  37.2604\n",
      " 36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072  36.8072\n",
      " 37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986  37.0986\n",
      " 33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123  33.4123\n",
      " 33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796  33.5796\n",
      " 33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796  33.8796\n",
      " 32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365  32.6365\n",
      "\n",
      "Columns 56 to 59 \n",
      " 45.6388  45.6388  45.6388  45.6388\n",
      " 43.0663  43.0663  43.0663  43.0663\n",
      " 40.6851  40.6851  40.6851  40.6851\n",
      " 37.2604  37.2604  37.2604  37.2604\n",
      " 36.8072  36.8072  36.8072  36.8072\n",
      " 37.0986  37.0986  37.0986  37.0986\n",
      " 33.4123  33.4123  33.4123  33.4123\n",
      " 33.5796  33.5796  33.5796  33.5796\n",
      " 33.8796  33.8796  33.8796  33.8796\n",
      " 32.6365  32.6365  32.6365  32.6365\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "88\n",
      "83\n",
      "70\n",
      "55\n",
      "48\n",
      "43\n",
      "43\n",
      "27\n",
      "20\n",
      "12\n",
      "torch.Size([880, 1])\n",
      "torch.Size([10, 88])\n",
      "[[ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          1.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.46666667  0.53333333 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.          1.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.06666667\n",
      "   0.93333333]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.53333333]]\n",
      "\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  1.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.4667  0.5333  ...   0.0000  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  1.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0667  0.9333\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.5333\n",
      "[torch.DoubleTensor of size 88x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0227  0.1886  0.0368  0.0129  0.2479 -0.1160 -0.0836 -0.1773 -0.2173  0.2858\n",
      "-0.0342  0.2089  0.0670  0.0013  0.2055 -0.0824 -0.0893 -0.1683 -0.2715  0.2652\n",
      "-0.0317  0.2039  0.0558  0.0001  0.2240 -0.0943 -0.0813 -0.1601 -0.2402  0.2773\n",
      "-0.0116  0.2070  0.0364  0.0128  0.2123 -0.1087 -0.0970 -0.1536 -0.2680  0.2619\n",
      "-0.0151  0.2123  0.0294  0.0086  0.2177 -0.1149 -0.0965 -0.1546 -0.2763  0.2667\n",
      "-0.0339  0.2078  0.0351  0.0128  0.1860 -0.0478 -0.1057 -0.1543 -0.3297  0.2537\n",
      "-0.0166  0.2073  0.0291 -0.0363  0.2183 -0.0994 -0.1044 -0.1655 -0.2652  0.2765\n",
      "-0.0624  0.2269  0.0838 -0.0274  0.1688 -0.0356 -0.1023 -0.1492 -0.3258  0.2465\n",
      "-0.0131  0.2073  0.0254 -0.0058  0.2437 -0.1354 -0.0992 -0.1595 -0.2390  0.2877\n",
      "-0.0158  0.2165  0.0410  0.0248  0.2134 -0.1159 -0.1006 -0.1581 -0.2972  0.2629\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287\n",
      " 38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884\n",
      " 37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008\n",
      " 35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660\n",
      " 33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898\n",
      " 32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785\n",
      " 34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703\n",
      " 32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253\n",
      " 32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811\n",
      " 31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307\n",
      "\n",
      "Columns 8 to 15 \n",
      " 38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287\n",
      " 38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884\n",
      " 37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008\n",
      " 35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660\n",
      " 33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898\n",
      " 32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785\n",
      " 34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703\n",
      " 32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253\n",
      " 32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811\n",
      " 31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307\n",
      "\n",
      "Columns 16 to 23 \n",
      " 38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287\n",
      " 38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884\n",
      " 37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008\n",
      " 35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660\n",
      " 33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898\n",
      " 32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785\n",
      " 34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703\n",
      " 32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253\n",
      " 32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811\n",
      " 31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307\n",
      "\n",
      "Columns 24 to 31 \n",
      " 38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287\n",
      " 38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884\n",
      " 37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008\n",
      " 35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660\n",
      " 33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898\n",
      " 32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785\n",
      " 34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703\n",
      " 32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253\n",
      " 32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811\n",
      " 31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307\n",
      "\n",
      "Columns 32 to 39 \n",
      " 38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287\n",
      " 38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884\n",
      " 37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008\n",
      " 35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660\n",
      " 33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898\n",
      " 32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785\n",
      " 34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703\n",
      " 32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253\n",
      " 32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811\n",
      " 31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307\n",
      "\n",
      "Columns 40 to 47 \n",
      " 38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287\n",
      " 38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884\n",
      " 37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008\n",
      " 35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660\n",
      " 33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898\n",
      " 32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785\n",
      " 34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703\n",
      " 32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253\n",
      " 32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811\n",
      " 31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307\n",
      "\n",
      "Columns 48 to 55 \n",
      " 38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287  38.7287\n",
      " 38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884  38.4884\n",
      " 37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008  37.3008\n",
      " 35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660  35.2660\n",
      " 33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898  33.4898\n",
      " 32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785  32.4785\n",
      " 34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703  34.7703\n",
      " 32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253  32.6253\n",
      " 32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811  32.1811\n",
      " 31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307  31.5307\n",
      "\n",
      "Columns 56 to 59 \n",
      " 38.7287  38.7287  38.7287  38.7287\n",
      " 38.4884  38.4884  38.4884  38.4884\n",
      " 37.3008  37.3008  37.3008  37.3008\n",
      " 35.2660  35.2660  35.2660  35.2660\n",
      " 33.4898  33.4898  33.4898  33.4898\n",
      " 32.4785  32.4785  32.4785  32.4785\n",
      " 34.7703  34.7703  34.7703  34.7703\n",
      " 32.6253  32.6253  32.6253  32.6253\n",
      " 32.1811  32.1811  32.1811  32.1811\n",
      " 31.5307  31.5307  31.5307  31.5307\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "162\n",
      "94\n",
      "94\n",
      "44\n",
      "31\n",
      "26\n",
      "25\n",
      "22\n",
      "17\n",
      "0\n",
      "torch.Size([1620, 1])\n",
      "torch.Size([10, 162])\n",
      "[[ 0.   1.   0.  ...,  0.   0.   0. ]\n",
      " [ 0.   1.   0.  ...,  0.   0.   0. ]\n",
      " [ 0.   0.   1.  ...,  0.   0.   0. ]\n",
      " ..., \n",
      " [ 0.   1.   0.  ...,  0.   0.   0. ]\n",
      " [ 0.   0.   0.  ...,  0.   0.   0.3]\n",
      " [ 0.   1.   0.  ...,  0.   0.   0. ]]\n",
      "\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  1.0000  ...   0.0000  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.3000\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.DoubleTensor of size 162x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0070  0.2047  0.0273  0.0028  0.2164 -0.1028 -0.1013 -0.1868 -0.2879  0.2710\n",
      "-0.0288  0.2104  0.0298 -0.0067  0.2302 -0.1192 -0.1082 -0.1710 -0.2610  0.2699\n",
      "-0.0236  0.1984  0.0429  0.0007  0.2257 -0.0987 -0.0850 -0.1629 -0.2438  0.2837\n",
      "-0.0354  0.2036  0.0596 -0.0057  0.2204 -0.0835 -0.0858 -0.1605 -0.2427  0.2737\n",
      "-0.0240  0.1871  0.0429  0.0295  0.2276 -0.1014 -0.0913 -0.1302 -0.2056  0.2658\n",
      "-0.0412  0.2268  0.0587 -0.0212  0.1879 -0.0756 -0.1004 -0.1469 -0.3381  0.2709\n",
      "-0.0601  0.2157  0.0586 -0.0176  0.2085 -0.0829 -0.0937 -0.1566 -0.3006  0.2698\n",
      "-0.0566  0.2024  0.0645  0.0288  0.2367 -0.0871 -0.0930 -0.1714 -0.1726  0.2620\n",
      "-0.0580  0.2340  0.0661 -0.0503  0.1702 -0.0487 -0.1132 -0.1515 -0.3522  0.2589\n",
      "-0.0030  0.1060  0.0168  0.0516  0.1027 -0.0574 -0.0493 -0.1035 -0.0448  0.0653\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163\n",
      " 66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182\n",
      " 68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720\n",
      " 60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730\n",
      " 59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600\n",
      " 57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969\n",
      " 57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392\n",
      " 58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239\n",
      " 55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529\n",
      " 53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806\n",
      "\n",
      "Columns 8 to 15 \n",
      " 84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163\n",
      " 66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182\n",
      " 68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720\n",
      " 60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730\n",
      " 59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600\n",
      " 57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969\n",
      " 57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392\n",
      " 58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239\n",
      " 55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529\n",
      " 53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806\n",
      "\n",
      "Columns 16 to 23 \n",
      " 84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163\n",
      " 66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182\n",
      " 68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720\n",
      " 60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730\n",
      " 59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600\n",
      " 57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969\n",
      " 57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392\n",
      " 58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239\n",
      " 55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529\n",
      " 53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806\n",
      "\n",
      "Columns 24 to 31 \n",
      " 84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163\n",
      " 66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182\n",
      " 68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720\n",
      " 60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730\n",
      " 59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600\n",
      " 57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969\n",
      " 57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392\n",
      " 58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239\n",
      " 55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529\n",
      " 53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806\n",
      "\n",
      "Columns 32 to 39 \n",
      " 84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163\n",
      " 66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182\n",
      " 68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720\n",
      " 60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730\n",
      " 59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600\n",
      " 57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969\n",
      " 57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392\n",
      " 58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239\n",
      " 55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529\n",
      " 53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806\n",
      "\n",
      "Columns 40 to 47 \n",
      " 84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163\n",
      " 66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182\n",
      " 68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720\n",
      " 60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730\n",
      " 59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600\n",
      " 57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969\n",
      " 57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392\n",
      " 58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239\n",
      " 55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529\n",
      " 53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806\n",
      "\n",
      "Columns 48 to 55 \n",
      " 84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163  84.1163\n",
      " 66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182  66.3182\n",
      " 68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720  68.9720\n",
      " 60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730  60.2730\n",
      " 59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600  59.3600\n",
      " 57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969  57.7969\n",
      " 57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392  57.4392\n",
      " 58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239  58.7239\n",
      " 55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529  55.1529\n",
      " 53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806  53.0806\n",
      "\n",
      "Columns 56 to 59 \n",
      " 84.1163  84.1163  84.1163  84.1163\n",
      " 66.3182  66.3182  66.3182  66.3182\n",
      " 68.9720  68.9720  68.9720  68.9720\n",
      " 60.2730  60.2730  60.2730  60.2730\n",
      " 59.3600  59.3600  59.3600  59.3600\n",
      " 57.7969  57.7969  57.7969  57.7969\n",
      " 57.4392  57.4392  57.4392  57.4392\n",
      " 58.7239  58.7239  58.7239  58.7239\n",
      " 55.1529  55.1529  55.1529  55.1529\n",
      " 53.0806  53.0806  53.0806  53.0806\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "71\n",
      "64\n",
      "46\n",
      "44\n",
      "44\n",
      "41\n",
      "31\n",
      "28\n",
      "22\n",
      "8\n",
      "torch.Size([710, 1])\n",
      "torch.Size([10, 71])\n",
      "[[ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          1.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.18333333  0.81666667 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.45        0.55        0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.63333333\n",
      "   0.36666667]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.81666667]]\n",
      "\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  1.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.1833  0.8167  ...   0.0000  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  0.0000  0.0000  ...   0.4500  0.5500  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.6333  0.3667\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.8167\n",
      "[torch.DoubleTensor of size 71x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0693  0.2222  0.0556 -0.0381  0.1701 -0.0368 -0.1105 -0.1637 -0.3336  0.2426\n",
      "-0.0528  0.2195  0.0637 -0.0191  0.1875 -0.0662 -0.1066 -0.1508 -0.3269  0.2662\n",
      "-0.0524  0.2145  0.0543 -0.0426  0.1795 -0.0439 -0.1089 -0.1452 -0.3265  0.2558\n",
      "-0.0524  0.2090  0.0499  0.0433  0.2483 -0.1199 -0.0934 -0.1700 -0.1898  0.2701\n",
      "-0.0438  0.2049  0.0675  0.0054  0.2161 -0.0738 -0.0951 -0.1494 -0.2345  0.2767\n",
      "-0.0283  0.1941  0.0654  0.0328  0.2213 -0.0930 -0.0832 -0.1324 -0.1982  0.2650\n",
      "-0.0081  0.1975  0.0161 -0.0047  0.2576 -0.1383 -0.0968 -0.1851 -0.2045  0.2901\n",
      "-0.0249  0.2120  0.0687  0.0069  0.2127 -0.0849 -0.0959 -0.1376 -0.2574  0.2686\n",
      "-0.0329  0.2066  0.0299  0.0149  0.2428 -0.1097 -0.0939 -0.1647 -0.2217  0.2692\n",
      "-0.0707  0.2224  0.0784  0.0241  0.1711 -0.0512 -0.0880 -0.1446 -0.3098  0.2352\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479\n",
      " 30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346\n",
      " 29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096\n",
      " 28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244\n",
      " 30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079\n",
      " 26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512\n",
      " 27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455\n",
      " 28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441\n",
      " 25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076\n",
      " 23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033\n",
      "\n",
      "Columns 8 to 15 \n",
      " 29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479\n",
      " 30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346\n",
      " 29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096\n",
      " 28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244\n",
      " 30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079\n",
      " 26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512\n",
      " 27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455\n",
      " 28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441\n",
      " 25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076\n",
      " 23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033\n",
      "\n",
      "Columns 16 to 23 \n",
      " 29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479\n",
      " 30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346\n",
      " 29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096\n",
      " 28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244\n",
      " 30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079\n",
      " 26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512\n",
      " 27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455\n",
      " 28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441\n",
      " 25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076\n",
      " 23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033\n",
      "\n",
      "Columns 24 to 31 \n",
      " 29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479\n",
      " 30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346\n",
      " 29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096\n",
      " 28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244\n",
      " 30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079\n",
      " 26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512\n",
      " 27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455\n",
      " 28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441\n",
      " 25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076\n",
      " 23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033\n",
      "\n",
      "Columns 32 to 39 \n",
      " 29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479\n",
      " 30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346\n",
      " 29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096\n",
      " 28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244\n",
      " 30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079\n",
      " 26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512\n",
      " 27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455\n",
      " 28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441\n",
      " 25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076\n",
      " 23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033\n",
      "\n",
      "Columns 40 to 47 \n",
      " 29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479\n",
      " 30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346\n",
      " 29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096\n",
      " 28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244\n",
      " 30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079\n",
      " 26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512\n",
      " 27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455\n",
      " 28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441\n",
      " 25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076\n",
      " 23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033\n",
      "\n",
      "Columns 48 to 55 \n",
      " 29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479  29.7479\n",
      " 30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346  30.3346\n",
      " 29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096  29.9096\n",
      " 28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244  28.2244\n",
      " 30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079  30.3079\n",
      " 26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512  26.8512\n",
      " 27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455  27.4455\n",
      " 28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441  28.1441\n",
      " 25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076  25.2076\n",
      " 23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033  23.8033\n",
      "\n",
      "Columns 56 to 59 \n",
      " 29.7479  29.7479  29.7479  29.7479\n",
      " 30.3346  30.3346  30.3346  30.3346\n",
      " 29.9096  29.9096  29.9096  29.9096\n",
      " 28.2244  28.2244  28.2244  28.2244\n",
      " 30.3079  30.3079  30.3079  30.3079\n",
      " 26.8512  26.8512  26.8512  26.8512\n",
      " 27.4455  27.4455  27.4455  27.4455\n",
      " 28.1441  28.1441  28.1441  28.1441\n",
      " 25.2076  25.2076  25.2076  25.2076\n",
      " 23.8033  23.8033  23.8033  23.8033\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "120\n",
      "89\n",
      "79\n",
      "77\n",
      "57\n",
      "51\n",
      "27\n",
      "23\n",
      "14\n",
      "0\n",
      "torch.Size([1200, 1])\n",
      "torch.Size([10, 120])\n",
      "[[ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  1. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  1.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]\n",
      " [ 0.  1.  0. ...,  0.  0.  0.]]\n",
      "\n",
      "    0     1     0  ...      0     0     0\n",
      "    0     1     0  ...      0     0     0\n",
      "    0     0     1  ...      0     0     0\n",
      "       ...          ⋱          ...       \n",
      "    0     0     0  ...      0     0     1\n",
      "    0     1     0  ...      0     0     0\n",
      "    0     1     0  ...      0     0     0\n",
      "[torch.DoubleTensor of size 120x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0486  0.2096  0.0421  0.0315  0.2224 -0.1170 -0.0933 -0.1727 -0.2647  0.2665\n",
      "-0.0401  0.2204  0.0263 -0.0174  0.2224 -0.1213 -0.1044 -0.1963 -0.2778  0.2794\n",
      "-0.0235  0.2155  0.0549 -0.0029  0.2062 -0.0965 -0.0893 -0.1406 -0.3154  0.2926\n",
      "-0.0226  0.1971  0.0429  0.0224  0.2490 -0.1203 -0.0867 -0.1780 -0.1834  0.2725\n",
      "-0.0313  0.2099  0.0406 -0.0275  0.1837 -0.0606 -0.0954 -0.1684 -0.3279  0.2648\n",
      " 0.0121  0.1947  0.0286  0.0409  0.2580 -0.1483 -0.0839 -0.1580 -0.1784  0.2869\n",
      "-0.0749  0.2279  0.0832  0.0494  0.1845 -0.0559 -0.0941 -0.1450 -0.2932  0.2376\n",
      "-0.0503  0.2002  0.0513  0.0460  0.2203 -0.0929 -0.0983 -0.1700 -0.2508  0.2578\n",
      "-0.0296  0.2082  0.0444 -0.0277  0.1978 -0.0647 -0.1024 -0.1635 -0.3101  0.2689\n",
      "-0.0035  0.1061  0.0173  0.0514  0.1023 -0.0569 -0.0495 -0.1031 -0.0453  0.0648\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237\n",
      " 52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351\n",
      " 54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168\n",
      " 51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443\n",
      " 45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051\n",
      " 48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371\n",
      " 44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966\n",
      " 42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555\n",
      " 40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598\n",
      " 40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122\n",
      "\n",
      "Columns 8 to 15 \n",
      " 48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237\n",
      " 52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351\n",
      " 54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168\n",
      " 51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443\n",
      " 45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051\n",
      " 48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371\n",
      " 44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966\n",
      " 42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555\n",
      " 40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598\n",
      " 40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122\n",
      "\n",
      "Columns 16 to 23 \n",
      " 48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237\n",
      " 52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351\n",
      " 54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168\n",
      " 51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443\n",
      " 45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051\n",
      " 48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371\n",
      " 44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966\n",
      " 42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555\n",
      " 40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598\n",
      " 40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122\n",
      "\n",
      "Columns 24 to 31 \n",
      " 48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237\n",
      " 52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351\n",
      " 54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168\n",
      " 51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443\n",
      " 45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051\n",
      " 48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371\n",
      " 44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966\n",
      " 42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555\n",
      " 40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598\n",
      " 40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122\n",
      "\n",
      "Columns 32 to 39 \n",
      " 48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237\n",
      " 52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351\n",
      " 54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168\n",
      " 51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443\n",
      " 45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051\n",
      " 48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371\n",
      " 44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966\n",
      " 42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555\n",
      " 40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598\n",
      " 40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122\n",
      "\n",
      "Columns 40 to 47 \n",
      " 48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237\n",
      " 52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351\n",
      " 54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168\n",
      " 51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443\n",
      " 45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051\n",
      " 48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371\n",
      " 44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966\n",
      " 42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555\n",
      " 40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598\n",
      " 40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122\n",
      "\n",
      "Columns 48 to 55 \n",
      " 48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237  48.9237\n",
      " 52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351  52.3351\n",
      " 54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168  54.5168\n",
      " 51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443  51.3443\n",
      " 45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051  45.4051\n",
      " 48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371  48.8371\n",
      " 44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966  44.4966\n",
      " 42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555  42.6555\n",
      " 40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598  40.4598\n",
      " 40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122  40.1122\n",
      "\n",
      "Columns 56 to 59 \n",
      " 48.9237  48.9237  48.9237  48.9237\n",
      " 52.3351  52.3351  52.3351  52.3351\n",
      " 54.5168  54.5168  54.5168  54.5168\n",
      " 51.3443  51.3443  51.3443  51.3443\n",
      " 45.4051  45.4051  45.4051  45.4051\n",
      " 48.8371  48.8371  48.8371  48.8371\n",
      " 44.4966  44.4966  44.4966  44.4966\n",
      " 42.6555  42.6555  42.6555  42.6555\n",
      " 40.4598  40.4598  40.4598  40.4598\n",
      " 40.1122  40.1122  40.1122  40.1122\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "112\n",
      "86\n",
      "85\n",
      "53\n",
      "42\n",
      "35\n",
      "24\n",
      "22\n",
      "20\n",
      "14\n",
      "torch.Size([1120, 1])\n",
      "torch.Size([10, 112])\n",
      "[[ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          1.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.86666667  0.13333333 ...,  0.          0.          0.        ]\n",
      " ..., \n",
      " [ 0.          0.          0.         ...,  0.          0.26666667\n",
      "   0.73333333]\n",
      " [ 0.          1.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          0.          0.         ...,  0.          0.          0.13333333]]\n",
      "\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  1.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.8667  0.1333  ...   0.0000  0.0000  0.0000\n",
      "          ...             ⋱             ...          \n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.2667  0.7333\n",
      " 0.0000  1.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      " 0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.1333\n",
      "[torch.DoubleTensor of size 112x60]\n",
      "\n",
      "torch.Size([10, 60])\n",
      "Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      "\n",
      "rnn_out :  Variable containing:\n",
      "-0.0471  0.2123  0.0564 -0.0047  0.2080 -0.0701 -0.0860 -0.1754 -0.2834  0.2673\n",
      "-0.0531  0.2105  0.0675 -0.0008  0.1955 -0.0557 -0.0818 -0.1432 -0.2951  0.2669\n",
      "-0.0386  0.2066  0.0569  0.0170  0.2212 -0.0994 -0.0840 -0.1606 -0.2643  0.2810\n",
      "-0.0569  0.2164  0.0655 -0.0119  0.1726 -0.0389 -0.1008 -0.1453 -0.3308  0.2555\n",
      "-0.0435  0.2050  0.0544  0.0363  0.2108 -0.0837 -0.0915 -0.1660 -0.2482  0.2559\n",
      "-0.0251  0.2093  0.0296 -0.0164  0.2430 -0.1160 -0.1002 -0.1785 -0.2284  0.2851\n",
      "-0.0721  0.2091  0.0603  0.0280  0.2141 -0.0737 -0.0965 -0.1835 -0.2472  0.2508\n",
      "-0.0698  0.2247  0.0817 -0.0090  0.1902 -0.0658 -0.0849 -0.1595 -0.2921  0.2675\n",
      "-0.0556  0.2258  0.0511 -0.0015  0.1504 -0.0269 -0.0953 -0.1720 -0.3969  0.2411\n",
      "-0.0568  0.2174  0.0434 -0.0249  0.1977 -0.0731 -0.1081 -0.1579 -0.2886  0.2488\n",
      "[torch.FloatTensor of size 10x10]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "cnn_out :  Variable containing:\n",
      "\n",
      "Columns 0 to 7 \n",
      " 51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782\n",
      " 47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584\n",
      " 48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010\n",
      " 42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659\n",
      " 46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929\n",
      " 40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236\n",
      " 40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464\n",
      " 41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949\n",
      " 38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986\n",
      " 38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755\n",
      "\n",
      "Columns 8 to 15 \n",
      " 51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782\n",
      " 47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584\n",
      " 48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010\n",
      " 42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659\n",
      " 46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929\n",
      " 40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236\n",
      " 40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464\n",
      " 41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949\n",
      " 38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986\n",
      " 38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755\n",
      "\n",
      "Columns 16 to 23 \n",
      " 51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782\n",
      " 47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584\n",
      " 48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010\n",
      " 42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659\n",
      " 46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929\n",
      " 40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236\n",
      " 40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464\n",
      " 41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949\n",
      " 38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986\n",
      " 38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755\n",
      "\n",
      "Columns 24 to 31 \n",
      " 51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782\n",
      " 47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584\n",
      " 48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010\n",
      " 42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659\n",
      " 46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929\n",
      " 40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236\n",
      " 40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464\n",
      " 41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949\n",
      " 38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986\n",
      " 38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755\n",
      "\n",
      "Columns 32 to 39 \n",
      " 51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782\n",
      " 47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584\n",
      " 48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010\n",
      " 42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659\n",
      " 46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929\n",
      " 40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236\n",
      " 40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464\n",
      " 41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949\n",
      " 38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986\n",
      " 38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755\n",
      "\n",
      "Columns 40 to 47 \n",
      " 51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782\n",
      " 47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584\n",
      " 48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010\n",
      " 42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659\n",
      " 46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929\n",
      " 40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236\n",
      " 40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464\n",
      " 41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949\n",
      " 38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986\n",
      " 38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755\n",
      "\n",
      "Columns 48 to 55 \n",
      " 51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782  51.7782\n",
      " 47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584  47.7584\n",
      " 48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010  48.1010\n",
      " 42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659  42.5659\n",
      " 46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929  46.1929\n",
      " 40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236  40.1236\n",
      " 40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464  40.6464\n",
      " 41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949  41.2949\n",
      " 38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986  38.9986\n",
      " 38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755  38.5755\n",
      "\n",
      "Columns 56 to 59 \n",
      " 51.7782  51.7782  51.7782  51.7782\n",
      " 47.7584  47.7584  47.7584  47.7584\n",
      " 48.1010  48.1010  48.1010  48.1010\n",
      " 42.5659  42.5659  42.5659  42.5659\n",
      " 46.1929  46.1929  46.1929  46.1929\n",
      " 40.1236  40.1236  40.1236  40.1236\n",
      " 40.6464  40.6464  40.6464  40.6464\n",
      " 41.2949  41.2949  41.2949  41.2949\n",
      " 38.9986  38.9986  38.9986  38.9986\n",
      " 38.5755  38.5755  38.5755  38.5755\n",
      "[torch.FloatTensor of size 10x60]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "nb_out :  Variable containing:\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "    0\n",
      "[torch.FloatTensor of size 10x1]\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 100])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([50, 100, 3])\n",
      "<class 'torch.FloatTensor'> torch.Size([50])\n",
      "<class 'torch.FloatTensor'> torch.Size([50])\n",
      "<class 'torch.FloatTensor'> torch.Size([50])\n",
      "<class 'torch.FloatTensor'> torch.Size([10, 50, 3])\n",
      "<class 'torch.FloatTensor'> torch.Size([10])\n",
      "<class 'torch.FloatTensor'> torch.Size([10])\n",
      "<class 'torch.FloatTensor'> torch.Size([10])\n",
      "<class 'torch.FloatTensor'> torch.Size([5, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([5])\n",
      "<class 'torch.FloatTensor'> torch.Size([1, 5])\n",
      "<class 'torch.FloatTensor'> torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "formatted_list = load_object(\"../Preprocessor/save_formatted_review.pkl\")\n",
    "test_classifier = classifierModule(100, 10)\n",
    "\n",
    "test_classifier.nb_model.add_FRlist(formatted_list)\n",
    "\n",
    "batch_list = test_classifier.resize_input(formatted_list)\n",
    "for bl in batch_list:\n",
    "    test_classifier(bl)\n",
    "\n",
    "for param in test_classifier.parameters():\n",
    "     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "### hyperparameters :\n",
    "\n",
    "1. learning_rate\n",
    "2. input_size\n",
    "3. batch_size\n",
    "4. optimizer\n",
    "5. loss function\n",
    "6. n_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "input_size = 100  # word2vec k size\n",
    "batch_size = 100\n",
    "n_epochs = 100\n",
    "\n",
    "model = classifierModule(input_size, batch_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_m1, 1), tf.argmax(y_m1_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction_m1, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# target이 0일 때, p가 1-s보다 작으면 +1\n",
    "# target이 1일 때, p가 1-s보다 크면 +1\n",
    "# -> (1-s-p)*(t-1/2) <= 0 일 때 +1\n",
    "def get_accuracy(outputs, targets, sensitivity):\n",
    "    result = 0\n",
    "    t = targets.data-0.5\n",
    "    x = (1-sensitivity-outputs.data[:, 1])*t\n",
    "    for y in x:\n",
    "        if y <= 0:\n",
    "            result+=1\n",
    "    return result\n",
    "    \n",
    "def get_targets(batch):\n",
    "    targets = list()\n",
    "    for formatted in batch:\n",
    "        if formatted.label:\n",
    "            targets.append(1)\n",
    "        else:\n",
    "            targets.append(0)\n",
    "            \n",
    "    return Variable(torch.tensor(targets), requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_net(self, train_list, validation_list, sensitivity = 0.5):\n",
    "    batch_list = test_classifier.resize_input(train_list)\n",
    "    \n",
    "    tacc_list = list()\n",
    "    vacc_list = list()\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        tacc_list.append(0)\n",
    "        vacc_list.append(0)\n",
    "        \n",
    "        for bl in batch_list:\n",
    "            outputs = model(bl)\n",
    "            targets = get_targets(bl)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            tacc_list[-1] += get_accuracy(outputs, targets, sensitivity)\n",
    "            \n",
    "        tacc_list[-1] = tacc_list[-1] / len(train_list)\n",
    "        vacc_list[-1] = get_accuracy(model(validation_list), get_targets(validation_list), sensitivity)\n",
    "    \n",
    "        print(\"epoch {}: loss.data[0] {:.3f}|  train acc {:.3f}|  validation acc {:.3f}\" \n",
    "              .format(epoch, loss.data[0], tacc_list[-1], vacc_list[-1]))\n",
    "        \n",
    "        if epoch > 5 and np.mean(np.array(tacc_list[-6:-1])) < np.mean(np.array(vacc_list[-6:-1])):\n",
    "            print(\"Seems like m1 starts to overfit, aborting training\")\n",
    "            break\n",
    "            \n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㄹ', 'ㄷ', 'ㄴ', 'ㅁ', 'ㄱ']\n",
      "['ㄱ', 'ㅁ', 'ㄴ', 'ㄷ', 'ㄹ']\n"
     ]
    }
   ],
   "source": [
    "a = [\"ㄱ\", \"ㄴ\", \"ㄷ\", \"ㄹ\", \"ㅁ\"]\n",
    "b = [4, 3, 2, 1, 0]\n",
    "c = [4, 2, 1, 0, 3]\n",
    "\n",
    "d = [x for _,x in sorted(zip(c,a))]\n",
    "print(d)\n",
    "list.reverse(d)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10]]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "a_ = list()\n",
    "for i in range(0, len(a), 3):\n",
    "    a_.append(a[i:i+3])\n",
    "print(a_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
