{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "    \n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "    \n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from rnn.ipynb\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable   \n",
    "\n",
    "sys.path.append(\"../Preprocessor\")\n",
    "import format_module\n",
    "\n",
    "import rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_size = 100  # word2vec k size\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class classifierModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(classifierModule, self).__init__()\n",
    "        self.rnn_model = rnn.RNN_model(input_size)\n",
    "        #TODO\n",
    "        \n",
    "    def encoder(self, formattedList):\n",
    "        length = len(formattedList)\n",
    "        contextList = [formattedList[i].context for i in range(length)]\n",
    "\n",
    "        lengths = torch.LongTensor([len(contextList[i]) for i in range(length)])\n",
    "        max_len = torch.max(lengths)\n",
    "        \n",
    "        data = np.zeros((length, max_len, input_size))\n",
    "\n",
    "        for i in range(length):\n",
    "            context = contextList[i]\n",
    "            if not (context.size == 0):\n",
    "                data[i, :context.shape[0],:] = context\n",
    "            else:\n",
    "                lengths[i] = 1\n",
    "            i+=1\n",
    "            \n",
    "        return self.sort_batch(torch.FloatTensor(data), formattedList, lengths)\n",
    "        \n",
    "    def sort_batch(self, context, formatted, seq_len):\n",
    "        batch_size = context.size(0)\n",
    "        sorted_seq_len, sorted_idx = seq_len.sort(0, descending = True)\n",
    "        \n",
    "        sorted_context = context[sorted_idx]\n",
    "        sorted_formatted = [formatted[i] for i in sorted_idx]\n",
    "\n",
    "        for f in sorted_formatted:\n",
    "            print(len(f.context))\n",
    "        \n",
    "        return Variable(sorted_context), sorted_formatted, sorted_seq_len\n",
    "    \n",
    "    def resize_input(self, input):\n",
    "        list_ = list()\n",
    "        for i in range(0, len(input), batch_size):\n",
    "            list_.append(input[i:i+batch_size])\n",
    "        return list_\n",
    "        \n",
    "    def forward(self, formatted_list, hidden=None):\n",
    "        batch_list = self.resize_input(formatted_list)\n",
    "        \n",
    "        for bl in batch_list:\n",
    "            context, formatted, lengths = self.encoder(bl)\n",
    "        \n",
    "            print(self.rnn_model(context, lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137\n",
      "120\n",
      "52\n",
      "42\n",
      "34\n",
      "32\n",
      "27\n",
      "25\n",
      "20\n",
      "9\n",
      "Variable containing:\n",
      "-0.1420  0.1213  0.0075  0.1448  0.0660  0.0837 -0.0373  0.0637 -0.1514 -0.0907\n",
      "-0.1196  0.0740  0.0165  0.1450  0.0418  0.0780 -0.0505  0.0316 -0.1397 -0.1102\n",
      "-0.1199  0.1044  0.0185  0.1344  0.0405  0.0855 -0.0480  0.0495 -0.1543 -0.0949\n",
      "-0.1159  0.0810  0.0137  0.1417  0.0246  0.0809 -0.0488  0.0497 -0.1431 -0.0975\n",
      "-0.1192  0.0940  0.0226  0.1372  0.0590  0.0889 -0.0527  0.0292 -0.1584 -0.1133\n",
      "-0.1181  0.0920  0.0179  0.1310  0.0375  0.0828 -0.0435  0.0408 -0.1404 -0.1052\n",
      "-0.1334  0.1062  0.0074  0.1341  0.0457  0.0846 -0.0421  0.0532 -0.1538 -0.0872\n",
      "-0.1277  0.0894  0.0109  0.1468  0.0319  0.0716 -0.0366  0.0626 -0.1431 -0.1031\n",
      "-0.1007  0.0946  0.0286  0.1254  0.0258  0.1038 -0.0532  0.0343 -0.1413 -0.1137\n",
      "-0.1168  0.0873  0.0212  0.1416  0.0054  0.0674 -0.0428  0.0498 -0.1332 -0.0936\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "141\n",
      "124\n",
      "104\n",
      "71\n",
      "63\n",
      "33\n",
      "27\n",
      "25\n",
      "19\n",
      "7\n",
      "Variable containing:\n",
      "-0.1305  0.1144  0.0154  0.1320  0.0385  0.0843 -0.0335  0.0626 -0.1541 -0.0840\n",
      "-0.1275  0.0970  0.0161  0.1386  0.0307  0.0757 -0.0383  0.0533 -0.1431 -0.1069\n",
      "-0.1151  0.0965  0.0282  0.1408  0.0277  0.0775 -0.0407  0.0609 -0.1412 -0.1358\n",
      "-0.1109  0.0882  0.0349  0.1226  0.0622  0.0885 -0.0491  0.0095 -0.1494 -0.1037\n",
      "-0.1220  0.1256  0.0235  0.1207 -0.0165  0.0836 -0.0390  0.0654 -0.1397 -0.1193\n",
      "-0.1094  0.1200  0.0197  0.1245 -0.0157  0.0960 -0.0433  0.0820 -0.1399 -0.1206\n",
      "-0.1138  0.1150  0.0160  0.1272 -0.0100  0.0962 -0.0447  0.0720 -0.1450 -0.1152\n",
      "-0.1124  0.1109  0.0357  0.1134 -0.0018  0.0873 -0.0456  0.0342 -0.1318 -0.1285\n",
      "-0.1256  0.0820  0.0144  0.1419  0.0530  0.0775 -0.0414  0.0457 -0.1348 -0.1044\n",
      "-0.1160  0.1129  0.0034  0.1236 -0.0336  0.0740 -0.0367  0.0950 -0.1317 -0.0981\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "112\n",
      "85\n",
      "83\n",
      "54\n",
      "45\n",
      "28\n",
      "22\n",
      "20\n",
      "13\n",
      "10\n",
      "Variable containing:\n",
      "-0.1223  0.0990  0.0259  0.1288  0.0277  0.0837 -0.0384  0.0314 -0.1462 -0.1145\n",
      "-0.1377  0.1011 -0.0028  0.1419  0.0321  0.0779 -0.0311  0.0789 -0.1503 -0.0928\n",
      "-0.1317  0.1159  0.0111  0.1344  0.0054  0.0809 -0.0421  0.0674 -0.1458 -0.1070\n",
      "-0.1084  0.1042  0.0296  0.1253 -0.0273  0.0812 -0.0499  0.0570 -0.1273 -0.1347\n",
      "-0.1308  0.0953  0.0072  0.1275  0.0216  0.0763 -0.0358  0.0573 -0.1440 -0.0896\n",
      "-0.1149  0.1217  0.0261  0.1264  0.0610  0.1084 -0.0432  0.0464 -0.1454 -0.1268\n",
      "-0.1305  0.1052  0.0222  0.1317  0.0135  0.0725 -0.0381  0.0430 -0.1441 -0.1150\n",
      "-0.1321  0.1057  0.0087  0.1303  0.0155  0.0728 -0.0479  0.0477 -0.1381 -0.1108\n",
      "-0.1091  0.1211  0.0239  0.1352  0.0235  0.0958 -0.0329  0.0784 -0.1350 -0.1360\n",
      "-0.1291  0.1294 -0.0018  0.1317  0.0177  0.0938 -0.0367  0.0918 -0.1516 -0.1078\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "86\n",
      "47\n",
      "46\n",
      "33\n",
      "27\n",
      "25\n",
      "15\n",
      "13\n",
      "8\n",
      "6\n",
      "Variable containing:\n",
      "-0.1131  0.1121  0.0260  0.1274  0.0107  0.0898 -0.0441  0.0552 -0.1390 -0.1214\n",
      "-0.1222  0.0911  0.0151  0.1396  0.0047  0.0683 -0.0473  0.0599 -0.1315 -0.1175\n",
      "-0.1229  0.1288  0.0224  0.1203  0.0156  0.0901 -0.0351  0.0664 -0.1389 -0.1208\n",
      "-0.1264  0.1151  0.0172  0.1298  0.0056  0.0844 -0.0428  0.0563 -0.1438 -0.1282\n",
      "-0.1096  0.1152  0.0348  0.1172  0.0200  0.0957 -0.0425  0.0383 -0.1459 -0.1117\n",
      "-0.1165  0.0881  0.0389  0.1204  0.0341  0.0793 -0.0523  0.0023 -0.1436 -0.1195\n",
      "-0.1164  0.0996  0.0289  0.1335  0.0457  0.1003 -0.0482  0.0209 -0.1496 -0.1250\n",
      "-0.1316  0.1292 -0.0087  0.1294 -0.0020  0.0901 -0.0302  0.1029 -0.1367 -0.1050\n",
      "-0.1130  0.1045  0.0213  0.1291  0.0250  0.0975 -0.0444  0.0505 -0.1504 -0.1094\n",
      "-0.1251  0.1028  0.0068  0.1312 -0.0050  0.0735 -0.0356  0.0627 -0.1416 -0.1122\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "96\n",
      "73\n",
      "68\n",
      "49\n",
      "41\n",
      "28\n",
      "16\n",
      "15\n",
      "15\n",
      "7\n",
      "Variable containing:\n",
      "\n",
      "Columns 0 to 5 \n",
      "-1.2151e-01  9.5299e-02  2.0662e-02  1.4337e-01  2.3351e-02  7.2770e-02\n",
      "-1.2666e-01  1.0164e-01 -2.3748e-03  1.3624e-01  3.4816e-02  9.2429e-02\n",
      "-1.2161e-01  9.6646e-02  2.5797e-02  1.3740e-01  3.2532e-02  7.6779e-02\n",
      "-1.0828e-01  1.1021e-01  3.4764e-02  1.2191e-01  3.1246e-02  9.5848e-02\n",
      "-1.1864e-01  1.1048e-01  2.4486e-02  1.3201e-01  1.2572e-06  8.1866e-02\n",
      "-1.2933e-01  9.0255e-02  4.5809e-03  1.3699e-01  5.7538e-02  8.6610e-02\n",
      "-1.1956e-01  1.0748e-01  1.1842e-02  1.2419e-01 -6.9356e-03  8.0816e-02\n",
      "-1.2929e-01  1.1251e-01  1.4802e-02  1.3998e-01  2.9748e-02  8.4351e-02\n",
      "-1.1985e-01  8.3636e-02  1.8047e-02  1.5467e-01  1.5331e-02  6.9675e-02\n",
      "-1.1865e-01  1.0006e-01  1.7818e-02  1.3661e-01  4.3236e-03  7.8946e-02\n",
      "\n",
      "Columns 6 to 9 \n",
      "-3.4812e-02  6.6948e-02 -1.2441e-01 -1.2522e-01\n",
      "-4.4441e-02  7.0274e-02 -1.5086e-01 -8.7134e-02\n",
      "-4.3858e-02  4.5465e-02 -1.3677e-01 -1.1956e-01\n",
      "-4.3368e-02  3.1840e-02 -1.4033e-01 -1.3120e-01\n",
      "-4.3170e-02  5.9928e-02 -1.3674e-01 -1.2323e-01\n",
      "-4.4556e-02  5.2072e-02 -1.4465e-01 -1.0097e-01\n",
      "-4.2296e-02  6.4225e-02 -1.4143e-01 -1.0120e-01\n",
      "-3.9096e-02  6.0941e-02 -1.4919e-01 -1.2043e-01\n",
      "-4.3717e-02  6.0414e-02 -1.3555e-01 -1.2303e-01\n",
      "-4.2224e-02  7.0491e-02 -1.3303e-01 -1.2191e-01\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "88\n",
      "83\n",
      "70\n",
      "55\n",
      "48\n",
      "43\n",
      "43\n",
      "27\n",
      "20\n",
      "12\n",
      "Variable containing:\n",
      "-0.1264  0.0865  0.0178  0.1447  0.0144  0.0598 -0.0354  0.0575 -0.1275 -0.1070\n",
      "-0.1260  0.0879  0.0093  0.1581  0.0193  0.0650 -0.0329  0.0883 -0.1344 -0.1055\n",
      "-0.1212  0.1130  0.0149  0.1270  0.0388  0.0941 -0.0471  0.0364 -0.1558 -0.0987\n",
      "-0.1173  0.1045  0.0297  0.1143  0.0089  0.0855 -0.0506  0.0302 -0.1387 -0.1222\n",
      "-0.1122  0.1055  0.0321  0.1196 -0.0071  0.0837 -0.0465  0.0391 -0.1317 -0.1278\n",
      "-0.1294  0.1165  0.0126  0.1278  0.0231  0.0812 -0.0526  0.0600 -0.1442 -0.1145\n",
      "-0.1230  0.0930  0.0095  0.1408  0.0286  0.0798 -0.0447  0.0738 -0.1304 -0.1179\n",
      "-0.1207  0.1135  0.0116  0.1330  0.0266  0.0925 -0.0424  0.0709 -0.1420 -0.1137\n",
      "-0.1239  0.1168  0.0195  0.1303  0.0278  0.0930 -0.0352  0.0567 -0.1482 -0.1165\n",
      "-0.1207  0.0938  0.0171  0.1365  0.0128  0.0751 -0.0434  0.0464 -0.1373 -0.1212\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "162\n",
      "94\n",
      "94\n",
      "44\n",
      "31\n",
      "26\n",
      "25\n",
      "22\n",
      "17\n",
      "0\n",
      "Variable containing:\n",
      "-0.1230  0.1383  0.0186  0.1189 -0.0045  0.0895 -0.0381  0.0691 -0.1469 -0.1159\n",
      "-0.1265  0.0912  0.0229  0.1356  0.0579  0.0826 -0.0513  0.0301 -0.1473 -0.1094\n",
      "-0.1157  0.0928  0.0126  0.1520 -0.0030  0.0739 -0.0431  0.0892 -0.1228 -0.1204\n",
      "-0.1180  0.1129  0.0190  0.1417  0.0215  0.0869 -0.0410  0.0599 -0.1379 -0.1179\n",
      "-0.1352  0.1148  0.0043  0.1381  0.0423  0.0804 -0.0443  0.0532 -0.1506 -0.0964\n",
      "-0.1110  0.1097  0.0166  0.1259 -0.0080  0.0852 -0.0445  0.0692 -0.1362 -0.1136\n",
      "-0.1232  0.1260  0.0258  0.1379  0.0290  0.0835 -0.0244  0.0853 -0.1403 -0.1311\n",
      "-0.1301  0.0903  0.0090  0.1366  0.0504  0.0808 -0.0413  0.0369 -0.1601 -0.0783\n",
      "-0.1174  0.1318  0.0095  0.1328  0.0170  0.0975 -0.0360  0.1036 -0.1440 -0.1147\n",
      "-0.0561  0.0363  0.0084  0.0683 -0.0226  0.0341 -0.0114  0.0125 -0.0873 -0.0630\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "71\n",
      "64\n",
      "46\n",
      "44\n",
      "44\n",
      "41\n",
      "31\n",
      "28\n",
      "22\n",
      "8\n",
      "Variable containing:\n",
      "-0.1143  0.0971  0.0122  0.1335  0.0327  0.0943 -0.0407  0.0570 -0.1285 -0.1322\n",
      "-0.1215  0.1176  0.0206  0.1344 -0.0330  0.0655 -0.0297  0.0880 -0.1252 -0.1047\n",
      "-0.1189  0.1063  0.0258  0.1347  0.0451  0.0969 -0.0450  0.0321 -0.1455 -0.1250\n",
      "-0.1277  0.1066  0.0105  0.1411  0.0240  0.0825 -0.0551  0.0590 -0.1417 -0.1203\n",
      "-0.1170  0.1122  0.0295  0.1289  0.0314  0.0934 -0.0372  0.0462 -0.1430 -0.1294\n",
      "-0.1237  0.0817 -0.0008  0.1456  0.0174  0.0750 -0.0394  0.0808 -0.1367 -0.0972\n",
      "-0.1314  0.1049  0.0107  0.1314  0.0195  0.0741 -0.0340  0.0636 -0.1451 -0.0965\n",
      "-0.1146  0.0786  0.0194  0.1479  0.0446  0.0900 -0.0528  0.0283 -0.1410 -0.1254\n",
      "-0.1080  0.0962  0.0259  0.1282  0.0299  0.0968 -0.0549  0.0351 -0.1414 -0.1217\n",
      "-0.1110  0.1212  0.0115  0.1237  0.0061  0.1012 -0.0441  0.0789 -0.1429 -0.1168\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "120\n",
      "89\n",
      "79\n",
      "77\n",
      "57\n",
      "51\n",
      "27\n",
      "23\n",
      "14\n",
      "0\n",
      "Variable containing:\n",
      "-0.1180  0.0964  0.0289  0.1368  0.0178  0.0848 -0.0496  0.0255 -0.1452 -0.1209\n",
      "-0.1160  0.1137  0.0378  0.1256  0.0153  0.0873 -0.0472  0.0329 -0.1392 -0.1334\n",
      "-0.1319  0.0989  0.0177  0.1325  0.0272  0.0720 -0.0459  0.0343 -0.1374 -0.1232\n",
      "-0.1236  0.1032  0.0216  0.1238  0.0267  0.0870 -0.0404  0.0355 -0.1472 -0.1124\n",
      "-0.1144  0.1002  0.0311  0.1196  0.0048  0.0837 -0.0476  0.0286 -0.1346 -0.1211\n",
      "-0.1240  0.1045  0.0242  0.1233  0.0017  0.0742 -0.0454  0.0364 -0.1385 -0.1304\n",
      "-0.1252  0.0995  0.0139  0.1222  0.0361  0.0721 -0.0444  0.0412 -0.1367 -0.1064\n",
      "-0.1304  0.1245  0.0135  0.1306  0.0319  0.0868 -0.0281  0.0823 -0.1461 -0.0994\n",
      "-0.1210  0.1065  0.0242  0.1296  0.0016  0.0791 -0.0390  0.0552 -0.1433 -0.1151\n",
      "-0.0539  0.0362  0.0121  0.0687 -0.0149  0.0359 -0.0105  0.0151 -0.0909 -0.0696\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "112\n",
      "86\n",
      "85\n",
      "53\n",
      "42\n",
      "35\n",
      "24\n",
      "22\n",
      "20\n",
      "14\n",
      "Variable containing:\n",
      "-0.1204  0.0945  0.0301  0.1258  0.0336  0.0822 -0.0512  0.0091 -0.1490 -0.1057\n",
      "-0.1215  0.1321  0.0349  0.1142  0.0263  0.0958 -0.0372  0.0227 -0.1530 -0.1117\n",
      "-0.1092  0.1074  0.0242  0.1329  0.0270  0.1022 -0.0375  0.0537 -0.1420 -0.1299\n",
      "-0.1144  0.0832  0.0178  0.1297 -0.0083  0.0765 -0.0476  0.0635 -0.1298 -0.1258\n",
      "-0.1341  0.0861  0.0033  0.1486  0.0484  0.0740 -0.0602  0.0383 -0.1404 -0.0973\n",
      "-0.1187  0.1085  0.0124  0.1418  0.0250  0.0871 -0.0317  0.0909 -0.1384 -0.1112\n",
      "-0.1201  0.0838  0.0267  0.1270  0.0153  0.0735 -0.0486  0.0333 -0.1417 -0.1117\n",
      "-0.1242  0.0955  0.0284  0.1264  0.0262  0.0849 -0.0436  0.0068 -0.1512 -0.1169\n",
      "-0.1155  0.1145  0.0190  0.1231  0.0181  0.0945 -0.0443  0.0609 -0.1389 -0.1251\n",
      "-0.1169  0.0959  0.0372  0.1223  0.0653  0.0949 -0.0459  0.0100 -0.1501 -0.1125\n",
      "[torch.FloatTensor of size 10x10]\n",
      "\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 100])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "formatted_list = load_object(\"../Preprocessor/save_formatted_review.pkl\")\n",
    "test_classifier = classifierModule()\n",
    "\n",
    "#print(formatted_list[0].context.shape)\n",
    "test_classifier(formatted_list)\n",
    "\n",
    "for param in test_classifier.parameters():\n",
    "     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㄹ', 'ㄷ', 'ㄴ', 'ㅁ', 'ㄱ']\n",
      "['ㄱ', 'ㅁ', 'ㄴ', 'ㄷ', 'ㄹ']\n"
     ]
    }
   ],
   "source": [
    "a = [\"ㄱ\", \"ㄴ\", \"ㄷ\", \"ㄹ\", \"ㅁ\"]\n",
    "b = [4, 3, 2, 1, 0]\n",
    "c = [4, 2, 1, 0, 3]\n",
    "\n",
    "d = [x for _,x in sorted(zip(c,a))]\n",
    "print(d)\n",
    "list.reverse(d)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 3], [4, 5, 6], [7, 8, 9], [10]]\n"
     ]
    }
   ],
   "source": [
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "a_ = list()\n",
    "for i in range(0, len(a), 3):\n",
    "    a_.append(a[i:i+3])\n",
    "print(a_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
