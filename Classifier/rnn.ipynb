{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Module\n",
    "\n",
    "rnn 버리고 lstm으로 먼저 구현해봅니다 <br />\n",
    "input : FormattedReview List <br />\n",
    "output : numpy array <br />\n",
    "\n",
    "FormattedReview\n",
    "- context              : Numpy array\n",
    "- context_bayes        : Tuple List\n",
    "- comp_similarity      : float\n",
    "- rate                 : float\n",
    "- reiteration_context  : float\n",
    "- reiteration_repeat   : float\n",
    "- post_time            : float\n",
    "- post_vip             : float\n",
    "- id                   : float\n",
    "\n",
    "- index                : int\n",
    "- label                : bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample code from <br />\n",
    "https://discuss.pytorch.org/t/example-of-many-to-one-lstm/1728/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "hidden_size = 10  # hyperparameter\n",
    "num_layers = 3    # hyperparameter\n",
    "p_dropout = 0.05  # hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort_batch from\n",
    "https://discuss.pytorch.org/t/about-the-variable-length-input-in-rnn-scenario/345/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, dropout = p_dropout)\n",
    "        \n",
    "    def forward(self, embeddings, lengths, hidden=None):\n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(embeddings, lengths.tolist(), batch_first=True)\n",
    "        output, hidden = self.rnn(packed, hidden)\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        \n",
    "        idx = (lengths-1).view(-1,1).expand(output.size(0), output.size(2)).unsqueeze(1)\n",
    "        \n",
    "        #print(output)\n",
    "        decoded = output.gather(1, Variable(idx)).squeeze()\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "formatted_list = load_object(\"../Preprocessor/save_formatted_review.pkl\")\n",
    "test_rnn = RNN_model()\n",
    "\n",
    "print(formatted_list[0].context.shape)\n",
    "test_rnn(formatted_list)\n",
    "\n",
    "#for param in test_rnn.parameters():\n",
    "#     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def sort_batch(data, seq_len):\n",
    "    batch_size = data.size(0)\n",
    "    sorted_seq_len, sorted_idx = seq_len.sort()\n",
    "    reverse_idx = torch.linspace(batch_size-1,0,batch_size).long()\n",
    "    sorted_seq_len = sorted_seq_len[reverse_idx]\n",
    "    sorted_data = data[sorted_idx][reverse_idx]\n",
    "        \n",
    "    return sorted_data, sorted_seq_len\n",
    "\n",
    "formatted_list = load_object(\"../Preprocessor/save_formatted_review.pkl\")[0:10]\n",
    "length = len(formatted_list)\n",
    "contextList = [formatted_list[i].context for i in range(length)]\n",
    "\n",
    "lengths = torch.LongTensor([len(contextList[i]) for i in range(length)])\n",
    "max_len = torch.max(lengths)\n",
    "\n",
    "data = np.zeros((length, max_len, input_size))\n",
    "\n",
    "for i in range(length):\n",
    "    context = contextList[i]\n",
    "    if not (context.size == 0):\n",
    "        data[i, :context.shape[0],:] = context\n",
    "    else:\n",
    "        data[i, 0, 0] = 1\n",
    "        lengths[i] = 1\n",
    "    i+=1\n",
    "    \n",
    "data = torch.FloatTensor(data)\n",
    "\n",
    "batch_size = data.size(0)\n",
    "sorted_seq_len, sorted_idx = lengths.sort()\n",
    "print(sorted_idx)\n",
    "reverse_idx = torch.linspace(batch_size-1,0,batch_size).long()\n",
    "print(reverse_idx)\n",
    "print(sorted_seq_len)\n",
    "sorted_seq_len = sorted_seq_len[reverse_idx]\n",
    "print(sorted_seq_len)\n",
    "\n",
    "print(\"\\n\\n\\n\", data)\n",
    "sorted_data = data[sorted_idx][reverse_idx]\n",
    "print(sorted_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "batch_size = 3\n",
    "max_length = 3\n",
    "hidden_size = 10\n",
    "n_layers =1\n",
    "\n",
    "# container\n",
    "batch_in = torch.zeros((batch_size, 1, max_length))\n",
    "\n",
    "#data\n",
    "vec_1 = torch.FloatTensor([[1, 2, 3]])\n",
    "vec_2 = torch.FloatTensor([[1, 2, 0]])\n",
    "vec_3 = torch.FloatTensor([[1, 0, 0]])\n",
    "\n",
    "batch_in[0] = vec_1r\n",
    "batch_in[1] = vec_2\n",
    "batch_in[2] = vec_3\n",
    "\n",
    "batch_in = Variable(batch_in)\n",
    "\n",
    "seq_lengths = [3,2,1] # list of integers holding information about the batch size at each sequence step\n",
    "\n",
    "# pack it\n",
    "pack = torch.nn.utils.rnn.pack_padded_sequence(batch_in, seq_lengths, batch_first=True)\n",
    "print(pack)\n",
    "\n",
    "rnn = nn.RNN(max_length, hidden_size, n_layers, batch_first=True) \n",
    "h0 = Variable(torch.randn(n_layers, batch_size, hidden_size))\n",
    "\n",
    "#forward \n",
    "out, _ = rnn(pack, h0)\n",
    "\n",
    "# unpack\n",
    "unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out)\n",
    "\n",
    "print(\"\\n\", unpacked)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "np.array([[]]).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
