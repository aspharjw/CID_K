{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Module\n",
    "\n",
    "rnn 버리고 lstm으로 먼저 구현해봅니다 <br />\n",
    "input : FormattedReview List <br />\n",
    "output : numpy array <br />\n",
    "\n",
    "FormattedReview\n",
    "- context              : Numpy array\n",
    "- context_bayes        : Tuple List\n",
    "- comp_similarity      : float\n",
    "- rate                 : float\n",
    "- reiteration_context  : float\n",
    "- reiteration_repeat   : float\n",
    "- post_time            : float\n",
    "- post_vip             : float\n",
    "- id                   : float\n",
    "\n",
    "- index                : int\n",
    "- label                : bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sample code from <br />\n",
    "https://discuss.pytorch.org/t/example-of-many-to-one-lstm/1728/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = nn.LSTM(in_size, classes_no, 2)\n",
    "input_seq = Variable(torch.randn(time_steps, batch_size, in_size))\n",
    "output_seq, _ = model(input_seq)\n",
    "last_output = output_seq[-1]\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "target = Variable(torch.LongTensor(batch_size).random_(0, classes_no-1))\n",
    "err = loss(last_output, target)\n",
    "err.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = Variable(torch.randn(3, 1, 5))\n",
    "h0 = Variable(torch.randn(1, 1, 10))\n",
    "c0 = Variable(torch.randn(1, 1, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      " -0.1007  0.0854 -0.2965  0.1249 -1.0662\n",
      "\n",
      "(1 ,.,.) = \n",
      "  0.6835  1.2083 -0.4033 -0.8664  0.4078\n",
      "\n",
      "(2 ,.,.) = \n",
      " -0.0301 -0.4181  0.0801  0.8633  1.7904\n",
      "[torch.FloatTensor of size 3x1x5]\n",
      "\n",
      "Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.3721 -0.2455  0.4047  0.0188 -0.0347 -0.1264  0.0526 -0.1881 -0.1872\n",
      "\n",
      "Columns 9 to 9 \n",
      "  -0.1837\n",
      "\n",
      "(1 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.2394 -0.0665  0.3482  0.1626 -0.0491 -0.1298  0.0904 -0.0084 -0.2787\n",
      "\n",
      "Columns 9 to 9 \n",
      "  -0.2293\n",
      "\n",
      "(2 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.2003 -0.0439  0.2087 -0.0600  0.1815  0.0176  0.0824  0.0505 -0.0520\n",
      "\n",
      "Columns 9 to 9 \n",
      "  -0.0149\n",
      "[torch.FloatTensor of size 3x1x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.LSTM(5, 10, 1)\n",
    "output, hn = rnn(input, (h0, c0))\n",
    "print(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "\n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        \n",
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for Jupyter Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "\n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "\n",
    "        print (\"importing Jupyter notebook from %s\" % path)\n",
    "\n",
    "        # load the notebook object\n",
    "        with io.open(path, 'r', encoding='utf-8') as f:\n",
    "            nb = read(f, 4)\n",
    "\n",
    "\n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "\n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "\n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod\n",
    "    \n",
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates Jupyter Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "\n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "\n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "\n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]\n",
    "    \n",
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable    \n",
    "\n",
    "input_size = 100  # word2vec k size\n",
    "hidden_size = 10  # hyperparameter\n",
    "num_layers = 3    # hyperparameter\n",
    "p_dropout = 0.05  # hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sort_batch from\n",
    "https://discuss.pytorch.org/t/about-the-variable-length-input-in-rnn-scenario/345/22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN_model, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, dropout = p_dropout)\n",
    "        \n",
    "    def encoder(self, formattedList):\n",
    "        length = len(formattedList)\n",
    "        contextList = [formattedList[i].context for i in range(length)]\n",
    "\n",
    "        lengths = torch.LongTensor([len(contextList[i]) for i in range(length)])\n",
    "        max_len = torch.max(lengths)\n",
    "\n",
    "        data = np.zeros((length, max_len, input_size))\n",
    "\n",
    "        for i in range(length):\n",
    "            context = contextList[i]\n",
    "            if not (context.size == 0):\n",
    "                data[i, :context.shape[0],:] = context\n",
    "            else:\n",
    "                lengths[i] = 1\n",
    "            i+=1\n",
    "            \n",
    "        return self.sort_batch(torch.FloatTensor(data), lengths)\n",
    "        \n",
    "    def sort_batch(self, data, seq_len):\n",
    "        batch_size = data.size(0)\n",
    "        sorted_seq_len, sorted_idx = seq_len.sort()\n",
    "        reverse_idx = torch.linspace(batch_size-1,0,batch_size).long()\n",
    "        sorted_seq_len = sorted_seq_len[reverse_idx]\n",
    "        sorted_data = data[sorted_idx][reverse_idx]\n",
    "        \n",
    "        return sorted_data, sorted_seq_len\n",
    "        \n",
    "    def forward(self, formattedList, hidden=None):\n",
    "        \n",
    "        embeddings, lengths = self.encoder(formattedList)\n",
    "        \n",
    "        packed = nn.utils.rnn.pack_padded_sequence(Variable(embeddings), lengths.tolist(), batch_first=True)\n",
    "        output, hidden = self.rnn(packed, hidden)\n",
    "        output, _ = nn.utils.rnn.pad_packed_sequence(output, batch_first=True)\n",
    "        \n",
    "        idx = (lengths-1).view(-1,1).expand(output.size(0), output.size(2)).unsqueeze(1)\n",
    "        \n",
    "        print(output)\n",
    "        decoded = output.gather(1, Variable(idx)).squeeze()\n",
    "        \n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):\n",
    "    with open(filename, 'rb') as input:\n",
    "        return pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from format_module.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import format_module\n",
    "import bookingreview\n",
    "import preprocessreview\n",
    "import wordvectormaker\n",
    "import postag_module\n",
    "import gensim\n",
    "import xl_to_br_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 100)\n",
      "Variable containing:\n",
      "( 0 ,.,.) = \n",
      " -0.0461  0.0323  0.0099  ...   0.1029  0.0343 -0.0305\n",
      " -0.0491  0.0480  0.0247  ...   0.1494  0.0522 -0.0513\n",
      " -0.0429  0.0605  0.0236  ...   0.1655  0.0645 -0.0767\n",
      "           ...             ⋱             ...          \n",
      " -0.0270  0.0444  0.0072  ...   0.1774  0.0445 -0.0925\n",
      " -0.0370  0.0427  0.0188  ...   0.1811  0.0445 -0.0966\n",
      " -0.0418  0.0470 -0.0020  ...   0.1629  0.0441 -0.1115\n",
      "\n",
      "( 1 ,.,.) = \n",
      " -0.0484  0.0300  0.0019  ...   0.0955  0.0303 -0.0358\n",
      " -0.0617  0.0519  0.0188  ...   0.1229  0.0439 -0.0596\n",
      " -0.0571  0.0614  0.0280  ...   0.1361  0.0515 -0.0690\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "( 2 ,.,.) = \n",
      " -0.0577  0.0260  0.0096  ...   0.0966  0.0200 -0.0346\n",
      " -0.0654  0.0336  0.0058  ...   0.1337  0.0353 -0.0632\n",
      " -0.0649  0.0410  0.0046  ...   0.1393  0.0307 -0.0732\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "... \n",
      "\n",
      "(97 ,.,.) = \n",
      " -0.0477  0.0294  0.0013  ...   0.0915  0.0315 -0.0331\n",
      " -0.0502  0.0482  0.0004  ...   0.1345  0.0493 -0.0572\n",
      " -0.0467  0.0518  0.0094  ...   0.1568  0.0533 -0.0679\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "(98 ,.,.) = \n",
      " -0.0481  0.0269 -0.0001  ...   0.0948  0.0299 -0.0341\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "\n",
      "(99 ,.,.) = \n",
      " -0.0479  0.0268  0.0000  ...   0.0948  0.0296 -0.0336\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "           ...             ⋱             ...          \n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "  0.0000  0.0000  0.0000  ...   0.0000  0.0000  0.0000\n",
      "[torch.FloatTensor of size 100x162x10]\n",
      "\n",
      "Variable containing:\n",
      "-0.0418  0.0470 -0.0020  ...   0.1629  0.0441 -0.1115\n",
      "-0.0426  0.0602 -0.0225  ...   0.1509  0.0645 -0.0972\n",
      "-0.0627  0.0724  0.0240  ...   0.1493  0.0489 -0.0922\n",
      "          ...             ⋱             ...          \n",
      "-0.0527  0.0491 -0.0023  ...   0.1529  0.0427 -0.0883\n",
      "-0.0481  0.0269 -0.0001  ...   0.0948  0.0299 -0.0341\n",
      "-0.0479  0.0268  0.0000  ...   0.0948  0.0296 -0.0336\n",
      "[torch.FloatTensor of size 100x10]\n",
      " \n",
      "\n",
      "\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 100])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40, 10])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n",
      "<class 'torch.FloatTensor'> torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "formatted_list = load_object(\"save_formatted_review.pkl\")\n",
    "test_rnn = RNN_model()\n",
    "\n",
    "print(formatted_list[0].context.shape)\n",
    "print(test_rnn(formatted_list), \"\\n\\n\")\n",
    "\n",
    "for param in test_rnn.parameters():\n",
    "     print(type(param.data), param.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=Variable containing:\n",
      " 1  2  3\n",
      " 1  2  0\n",
      " 1  0  0\n",
      "[torch.FloatTensor of size 3x3]\n",
      ", batch_sizes=[3])\n",
      "\n",
      " Variable containing:\n",
      "(0 ,.,.) = \n",
      "\n",
      "Columns 0 to 8 \n",
      "   0.8215 -0.0527  0.7637  0.9655 -0.4354  0.5745  0.7437  0.8519  0.8935\n",
      "  0.6907  0.5297  0.2629  0.0165 -0.3369 -0.4116  0.5638  0.7357  0.9065\n",
      "  0.5517  0.4149  0.0342  0.0964  0.3720  0.7712  0.7045  0.1289 -0.7368\n",
      "\n",
      "Columns 9 to 9 \n",
      "  -0.9333\n",
      "  0.3643\n",
      " -0.8083\n",
      "[torch.FloatTensor of size 1x3x10]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "max_length = 3\n",
    "hidden_size = 10\n",
    "n_layers =1\n",
    "\n",
    "# container\n",
    "batch_in = torch.zeros((batch_size, 1, max_length))\n",
    "\n",
    "#data\n",
    "vec_1 = torch.FloatTensor([[1, 2, 3]])\n",
    "vec_2 = torch.FloatTensor([[1, 2, 0]])\n",
    "vec_3 = torch.FloatTensor([[1, 0, 0]])\n",
    "\n",
    "batch_in[0] = vec_1\n",
    "batch_in[1] = vec_2\n",
    "batch_in[2] = vec_3\n",
    "\n",
    "batch_in = Variable(batch_in)\n",
    "\n",
    "seq_lengths = [3,2,1] # list of integers holding information about the batch size at each sequence step\n",
    "\n",
    "# pack it\n",
    "pack = torch.nn.utils.rnn.pack_padded_sequence(batch_in, seq_lengths, batch_first=True)\n",
    "print(pack)\n",
    "\n",
    "rnn = nn.RNN(max_length, hidden_size, n_layers, batch_first=True) \n",
    "h0 = Variable(torch.randn(n_layers, batch_size, hidden_size))\n",
    "\n",
    "#forward \n",
    "out, _ = rnn(pack, h0)\n",
    "\n",
    "# unpack\n",
    "unpacked, unpacked_len = torch.nn.utils.rnn.pad_packed_sequence(out)\n",
    "\n",
    "print(\"\\n\", unpacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
